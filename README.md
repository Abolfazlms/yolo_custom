ğŸ“¦ YOLOv3 Real-Time Object Detection (OpenCV + Python)








A real-time object detection system using YOLOv3, OpenCV, and a standard webcam.
Each detected object is drawn with a unique, consistent class-based color, and labels include confidence percentages.

Perfect for beginners exploring computer vision, students presenting AI demos, or developers building real-time recognition systems.

ğŸš€ Features

âœ”ï¸ Real-time detection via webcam

âœ”ï¸ YOLOv3 + OpenCV DNN module (no GPU required)

âœ”ï¸ Unique & persistent color for every object class

âœ”ï¸ Confidence thresholding + Non-Maximum Suppression

âœ”ï¸ User-friendly visualization with bounding boxes and labels

âœ”ï¸ Clean modular code (find_objects() for detection logic)

ğŸ“‚ Project Structure
.
â”œâ”€â”€ yolo_object_detection.py
â”œâ”€â”€ yolov3.cfg
â”œâ”€â”€ yolov3.weights
â”œâ”€â”€ coco.names
â””â”€â”€ README.md

ğŸ“¥ Download YOLOv3 Weights

Download the official YOLOv3 weights (required):

ğŸ”— https://pjreddie.com/media/files/yolov3.weights

(or use your Google Drive link if preferred)

Place them in the same folder as the script.

ğŸ› ï¸ Installation
1ï¸âƒ£ Install dependencies
pip install opencv-python numpy

2ï¸âƒ£ Run the script
python yolo_object_detection.py

ğŸ® Controls
Key	Action
q	Quit the webcam and close program
ğŸ§  How It Works

The webcam frame is converted into a YOLO input blob.

The network performs a forward pass to get predictions.

For each detection:

The class ID is found.

Confidence is checked.

Bounding box is scaled to the actual image.

Non-Maximum Suppression (NMS) removes overlapping detections.

Each class is drawn using a unique, random but stable BGR color.

ğŸ–¼ï¸ Output Example

Real-time bounding boxes look like this:

[PERSON 97%]
[CHAIR 84%]
[DOG 91%]


Each category has its own color for easy visualization.

ğŸ“Œ Code Highlights
Unique color per class
colors = np.random.uniform(50, 255, size=(len(coco_classes), 3))

Drawing boxes
cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

Applying NMS
indices = cv2.dnn.NMSBoxes(bbox, confidences, confidence_threshold, nms_threshold)

ğŸ“Œ Future Improvements

ğŸ”¹ Add FPS counter

ğŸ”¹ Enable GPU acceleration (CUDA build of OpenCV)

ğŸ”¹ Add object tracking (SORT / DeepSORT)

ğŸ”¹ Save detections to file

ğŸ”¹ Run on video files instead of webcam

ğŸ“œ License

MIT License â€” free to use, modify, and distribute.